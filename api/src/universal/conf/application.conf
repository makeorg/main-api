// Application.conf file for docker

akka {

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "localhost"
      hostname = ${?HOSTNAME}
      hostname = ${?TCP_HOST}
      port = 2553
      port = ${?TCP_PORT}
    }
  }

  cluster {
    seed-nodes = []
    seed-nodes += ${?SEED_0}
    seed-nodes += ${?SEED_1}
    seed-nodes += ${?SEED_2}
    seed-nodes += ${?SEED_3}
    seed-nodes += ${?SEED_4}

    roles = ["worker"]

    sharding {
      guardian-name = sharding
      remember-entities = on
      state-store-mode = persistence
      role = "worker"

      snapshot-plugin-id = "cassandra-snapshot-store"
      journal-plugin-id = "cassandra-journal"
    }
  }

  persistence {
    journal {
      plugin = cassandra-journal
    }
    snapshot-store {
      plugin = cassandra-snapshot-store
    }
    role = "worker"
  }
}

make-api {

  cluster {
    # Name of the akka actor systems, to allow multiple systems on the same consul
    name = "make-api"
    name = ${?CONTEXT_NAME}

    backend = "consul"

    consul {
      host = "locahost"
      host = ${?CONSUL_HOST}
      http-port = 8500
      http-port = ${?CONSUL_HTTP_PORT}
    }

    # Interval on which heartbeat is updated
    heartbeat-interval = "30 seconds"
    # Time of the consul session, kept small in order to react quickly on seeds down
    session-timeout = "30 seconds"
    # Number of connection retries before trying to become a seed at start time
    retries-before-seeding = 3
    # duration between each session renew
    session-renew-interval = "20 seconds"
    # duration needed to declare a node as down
    node-timeout = "2 minutes"
    # interval to cleanup timeout nodes
    cleanup-interval = "1 hour"

  }

  passivate-timeout = "2 minutes"

  http {
    host = "0.0.0.0"
    host = ${?HTTP_HOST}
    port = 9000
    port = ${?HTTP_PORT}
  }

  dev {
    embedded-elastic-search = false
    send-test-data = false
  }

  kafka {
    connection-string = "localhost:9092"
    connection-string = ${?KAFKA_URI}
    poll-timeout = 10000
    schema-registry = "http://localhost:18081"
    schema-registry = ${?AVRO_REGISTRY_URL}
    topics {
      citizens = "citizens"
      citizens = ${?KAFKA_CITIZEN_TOPIC}
      propositions = "propositions"
      propositions = ${?KAFKA_PROPOSITIONS_TOPIC}
      votes = "votes"
      votes = ${?KAFKA_VOTE_TOPIC}
    }
  }

  elasticSearch {
    host = "localhost"
    host = ${?ES_HOST}
    port = 9200
    port = ${?ES_PORT}
  }

  database {
    jdbc-url = "jdbc:postgresql://localhost:26257/makeapi"
    jdbc-url = ${?JDBC_URL}
    user = "root"
    user = ${?DB_USER}
    password = ""
    password = ${?DB_PASSWORD}
    pools {
      read {
        connections = 50
      }
      write {
        connections = 20
      }
    }
    auto-create-db-schemas = true
  }
}


cassandra-journal.contact-points = []
cassandra-journal.contact-points += ${?CASSANDRA_0}
cassandra-journal.contact-points += ${?CASSANDRA_1}
cassandra-journal.contact-points += ${?CASSANDRA_2}
cassandra-journal.contact-points += ${?CASSANDRA_3}
cassandra-journal.contact-points += ${?CASSANDRA_4}

cassandra-journal.port = ${?CASSANDRA_PORT}
cassandra-journal.keyspace = ${?CASSANDRA_KEYSPACE}
cassandra-journal.replication-strategy = ${?CASSANDRA_REPLICATION_STRATEGY}


cassandra-snapshot-store.contact-points = []
cassandra-snapshot-store.contact-points += ${?CASSANDRA_0}
cassandra-snapshot-store.contact-points += ${?CASSANDRA_1}
cassandra-snapshot-store.contact-points += ${?CASSANDRA_2}
cassandra-snapshot-store.contact-points += ${?CASSANDRA_3}
cassandra-snapshot-store.contact-points += ${?CASSANDRA_4}

cassandra-snapshot-store.port = ${?CASSANDRA_PORT}
cassandra-snapshot-store.keyspace = ${?CASSANDRA_KEYSPACE}
cassandra-snapshot-store.replication-strategy = ${?CASSANDRA_REPLICATION_STRATEGY}


