akka {

  actor {

    debug {
      lifecycle = off
      log-sent-messages = off
    }

    provider = "akka.cluster.ClusterActorRefProvider"

    serializers {
      make-serializer = "org.make.api.technical.MakeEventSerializer"
      kryo-serializer = "io.altoo.akka.serialization.kryo.KryoSerializer"
    }
    serialization-bindings {
      "org.make.core.MakeSerializable" = make-serializer
      "org.make.api.technical.ActorProtocol" = kryo-serializer
    }
  }

  cluster {
    role {
      seed {
        min-nr-of-members = 1
      }
      worker {
        min-nr-of-members = 1
      }
    }
    roles = ["seed", "worker"]

    run-coordinated-shutdown-when-down = true

    seed-nodes = []

    sharding {
      guardian-name = sharding
      remember-entities = false
      state-store-mode = ddata
      role = "worker"
    }
  }

  extensions = [org.make.constructr.ConstructrExtension]

  http {
    client.connecting-timeout = "2 seconds"
    client.parsing.max-response-reason-length = 128
    parsing.max-content-length = 524288 // 512ko
    host-connection-pool.idle-timeout = infinite
    server.preview.enable-http2 = off
  }

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  persistence {
    cassandra {
      cleanup.dry-run = false
      events-by-tag.enabled = false
      journal {
        keyspace = "makeapi"
        keyspace = ${?CASSANDRA_KEYSPACE}
        keyspace-autocreate = true
        tables-autocreate = true
        replication-factor = 1
      }
      snapshot {
        keyspace = "makeapi"
        keyspace = ${?CASSANDRA_KEYSPACE}
        keyspace-autocreate = true
        tables-autocreate = true
        replication-factor = 1
      }
    }
    journal {
      plugin = "make-api.event-sourcing.technical.journal"
    }
    snapshot-store {
      plugin = "make-api.event-sourcing.technical.snapshot"
    }
    role = "worker"
  }

  remote {
    artery {
      enabled = on
      transport = tcp
      canonical.hostname = "localhost"
      canonical.hostname = ${?HOSTNAME}
      canonical.hostname = ${?TCP_HOST}
      canonical.port = 2551
      canonical.port = ${?TCP_PORT}
      advanced.maximum-frame-size = 1048576
    }
    log-remote-lifecycle-events = off
  }
}

akka-kryo-serialization {
  type = "graph"
  id-strategy = "default"
  post-serialization-transformations = "lz4"
  implicit-registration-logging = true
}

constructr {
  coordination {
    nodes = ${make-api.zookeeper.url}

    zookeeper.rootpath = "/make-api"
    zookeeper.rootpath = ${?ZOOKEEPER_ROOTPATH}
  }

  coordination-timeout = "3 seconds"
  join-timeout = "15 seconds"
  max-nr-of-seed-nodes = -1
  refresh-interval = "10 seconds"
  nr-of-retries = 2
  retry-delay = "2 seconds"
  ttl-factor = 3.1
}

datastax-java-driver {
  advanced.reconnect-on-init = true
  basic {
    port = 9042
    port = ${?CASSANDRA_PORT}
    contact-points = ["127.0.0.1:"${datastax-java-driver.basic.port}]
    load-balancing-policy.local-datacenter = "datacenter1"
  }
}

kamon {

  akka.ask-pattern-timeout-warning = "lightweight"

  prometheus {
    embedded-server {
      # Hostname and port used by the embedded web server to publish the scraping enpoint.
      hostname = "0.0.0.0"
      hostname = ${?HTTP_HOST}
      metrics-path = "/metrics"
      port = 4000
      port = ${?MONITORING_PORT}
    }
  }

  modules.host-metrics.enabled = false

  cluster-sharding {
    regions = [
      "proposal",
      "user-history",
      "session-history",
      "job"
    ],
    refresh-interval = "20 seconds"
    stats-timeout = "5 seconds"
  }

  instrumentation {
    akka{
      http {
        server {
          propagation {
            enabled = yes
            channel = default
          }

          tracing {
            response-headers {
              trace-id = none
              span-id = none
            }
            operations.default = "unknown"

          }
        }

        client {
          propagation {
            enabled = yes
            channel = default
          }
          tracing.operations.name-generator = "org.make.api.technical.MakeClientOperationNameGenerator"
        }
      }
      filters {
        actors {
          doomsday-wildcard = on
          track {
            includes = ["make-api/user/**"]
            excludes = ["make-api/system/**"]
          }
        }
        dispatchers {
          includes = [
            "akka.actor.default-dispatcher",
            "make-api.kafka.dispatcher",
            "make-api.elasticSearch.dispatcher",
            "make-api.mail-jet.dispatcher",
            "make-api.webflow.dispatcher"
          ]
        }
        routers {
          includes = [ ]
          excludes = [ "make-api/system/**" ]
        }
      }

    }
  }
}

make-api {

  authentication {
    default-client-id = "0cdd82cb-5cc0-4875-bb54-5c3709449429"
    default-client-id = ${?DEFAULT_CLIENT_ID}
    default-client-secret = "f4f7076e-6337-41d5-b000-3726ead0ae41"
    default-client-secret = ${?DEFAULT_CLIENT_SECRET}
  }

  authorized-cors-uri: ["http://localhost:9009", "http://localhost:4242", "http://localhost:3000"]
  authorized-cors-uri: ${?AUTHORIZED_CORS_URI}

  cookie-visitor {
    is-secure = false
    is-secure = ${?VISITOR_COOKIE_IS_SECURE}
    name = "make-visitor-id"
    name = ${?VISITOR_COOKIE_IS_SECURE}
    created-at-name = "make-visitor-created-at"
    created-at-name = ${?VISITOR_COOKIE_IS_SECURE}
    domain = "localhost"
  }

  cookie-session {
    lifetime = "20 minutes"
    lifetime = ${?SESSION_COOKIE_LIFETIME}
    is-secure = false
    is-secure = ${?SESSION_COOKIE_IS_SECURE}
    name = "make-session-id"
    name = ${?SESSION_COOKIE_IS_SECURE}
    expiration-name = "make-session-id-expiration"
    expiration-name = ${?SESSION_COOKIE_IS_SECURE}
    domain = "localhost"
  }

  cookie-secure {
    is-secure = false
    is-secure = ${?SECURE_COOKIE_IS_SECURE}
    name = "make-secure"
    name = ${?SECURE_COOKIE_IS_SECURE}
    expiration-name = "make-secure-expiration"
    expiration-name = ${?SECURE_COOKIE_IS_SECURE}
    domain = "localhost"
  }

  cookie-user-id {
    is-secure = false
    is-secure = ${?USER_ID_COOKIE_IS_SECURE}
    name = "make-user-id"
    name = ${?USER_ID_COOKIE_IS_SECURE}
    domain = "localhost"
  }

  database {
    jdbc-url = "jdbc:postgresql://localhost:26257/makeapi"
    jdbc-url = ${?JDBC_URL}
    user = "root"
    user = ${?DB_USER}
    password = ""
    password = ${?DB_PASSWORD}
    pools {
      read {
        max-total = 30
        initial-size = 10
        max-idle = 10
      }
      write {
        max-total = 80
        initial-size = 10
        max-idle = 10
      }
    }
    migration {
      init-schema = true
      baseline-version = "1.1"
      repair = false
      repair = ${?DB_REPAIR_MIGRATIONS}
    }
  }

  default-admin {
    first-name: "admin"
    email: "admin@make.org"
    password: "admin"
  }

  default-user-anonymous-participation = false
  default-user-anonymous-participation = ${?DEFAULT_ANONYMOUS_PARTICIPATION}

  duplicate-detector {
    max-results = 25
    max-results = ${?DUPLICATE_DETECTOR_MAX_RESULTS}
  }

  elasticSearch {
    dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"
      thread-pool-executor {
        fixed-pool-size = 16
      }
      throughput = 1
    }
    connection-string = "localhost:9200"
    connection-string = ${?ES_URL}
    index-name = "make"
    index-name = ${?ES_INDEX_NAME}
    idea-alias-name = "idea"
    idea-alias-name = ${?ES_IDEA_ALIAS_NAME}
    organisation-alias-name = "organisation"
    organisation-alias-name = ${?ES_ORGANISATION_ALIAS_NAME}
    proposal-alias-name = "proposal"
    proposal-alias-name = ${?ES_PROPOSAL_ALIAS_NAME}
    operation-of-question-alias-name = "operation-of-question"
    operation-of-question-alias-name = ${?ES_OPERATION_OF_QUESTION_ALIAS_NAME}
    post-alias-name = "post"
    post-alias-name = ${?ES_POST_ALIAS_NAME}
    buffer-size = 100
    buffer-size = ${?ES_BUFFER_SIZE}
    bulk-size = 100
    bulk-size = ${?ES_BULK_SIZE}
  }

  environment = "dev"

  event-sourcing {

    proposals = ${akka.persistence.cassandra}
    proposals {
      journal {
        table = "proposal_events"
        metadata-table = "proposal_events_metadata"
        config-table = "proposal_events_config"
        all-persistence-ids-table = "proposal_ids"
      }

      snapshot {
        table = "proposal_snapshots"
        metadata-table = "proposal_snapshots_metadata"
        config-table = "proposals_snapshot_config"
      }

    }

    sessions = ${akka.persistence.cassandra}
    sessions {
      journal {
        table = "session_events"
        metadata-table = "session_events_metadata"
        config-table = "session_events_config"
        all-persistence-ids-table = "session_ids"
      }

      snapshot {
        table = "session_snapshots"
        metadata-table = "session_snapshots_metadata"
        config-table = "session_snapshot_config"
      }
    }

    users = ${akka.persistence.cassandra}
    users {
      journal {
        table = "user_events"
        metadata-table = "user_events_metadata"
        config-table = "user_events_config"
        all-persistence-ids-table = "user_ids"
      }

      snapshot {
        table = "user_snapshots"
        metadata-table = "user_snapshots_metadata"
        config-table = "user_snapshot_config"
      }
    }

    technical = ${akka.persistence.cassandra}
    technical {
      journal {
        table = "technical_events"
        metadata-table = "technical_events_metadata"
        config-table = "technical_events_config"
        all-persistence-ids-table = "technical_ids"
      }

      snapshot {
        table = "technical_snapshots"
        metadata-table = "technical_snapshots_metadata"
        config-table = "technical_snapshot_config"
      }
    }

    jobs = ${akka.persistence.cassandra}
    jobs {
      journal {
        table = "job_events"
        metadata-table = "job_events_metadata"
        config-table = "job_events_config"
        all-persistence-ids-table = "job_ids"
      }

      snapshot {
        table = "job_snapshots"
        metadata-table = "job_snapshots_metadata"
        config-table = "job_snapshot_config"
      }
    }
  }

  http {
    host = "0.0.0.0"
    host = ${?HTTP_HOST}
    port = 9000
    port = ${?HTTP_PORT}
    ssl = false
    ssl = ${?SSL}
  }

  kafka {
    dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"
      thread-pool-executor {
        fixed-pool-size = 32
      }
      throughput = 1
    }

    connection-string = "localhost:9092"
    connection-string = ${?KAFKA_URI}
    poll-timeout = 10000
    schema-registry = "http://localhost:18081"
    schema-registry = ${?AVRO_REGISTRY_URL}
    topics {
      concertation = "concertation"
      concertation = ${?KAFKA_CONCERTATION_TOPIC}
      demographics = "demographics"
      demographics = ${?KAFKA_DEMOGRAPHICS_TOPIC}
      // Topic was changed when data structure changed.
      emails = "emails-v2"
      emails = ${?KAFKA_EMAIL_TOPIC}
      ideas = "ideas-v2"
      ideas = ${?KAFKA_IDEAS_TOPIC}
      mailjet-events = "mailjet-v2"
      mailjet-events = ${?KAFKA_MAILJET_EVENT_TOPIC}
      proposals = "proposals-v2"
      proposals = ${?KAFKA_PROPOSALS_TOPIC}
      // Topic was changed when data structure changed.
      tracking-events = "tracking-v2"
      tracking-events = ${?KAFKA_TRACKING_EVENTS_TOPIC}
      users = "users-v2"
      users = ${?KAFKA_USER_TOPIC}
    }
  }

  mail-jet {
    dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"
      thread-pool-executor {
        fixed-pool-size = 32
      }
      throughput = 1
    }
    http-buffer-size = 100
    url = "https://api.mailjet.com"
    api-key = "transactional-emails-api-key"
    api-key = ${?MAILJET_API_KEY}
    secret-key = "transactional-emails-secret-key"
    secret-key = ${?MAILJET_SECRET_KEY}
    campaign-api-key = "contact-list-api-key"
    campaign-api-key = ${?CAMPAIGN_MAILJET_API_KEY}
    campaign-secret-key = "contact-list-secret-key"
    campaign-secret-key = ${?CAMPAIGN_MAILJET_SECRET_KEY}
    basic-auth-login = "make-mailjet"
    basic-auth-login = ${?MAILJET_AUTH_LOGIN}
    basic-auth-password = "ZUtV95wY56YziEr5"
    basic-auth-password = ${?MAILJET_AUTH_PASSWORD}

    error-reporting {
      recipient-name = "emailing"
      recipient = "emailing@make.org"
    }

    user-list {
      hard-bounce-list-id = "2412499"
      hard-bounce-list-id = ${?MAILJET_HARD_BOUNCE_LIST_ID}
      unsubscribe-list-id = "2412500"
      unsubscribe-list-id = ${?MAILJET_UNSUB_LIST_ID}
      opt-in-list-id = "2412498"
      opt-in-list-id = ${?MAILJET_OPTIN_LIST_ID}
      batch-size = 1000
      batch-size = ${?MAILJET_USER_LIST_BATCH_SIZE}
      csv-directory = "/tmp/make/crm"
      csv-directory = ${?CRM-CSV-DIRECTORY}
      csv-bytes-size = 16777216
      csv-bytes-size = ${?MAILJET_CSV_SIZE}
    }

    templates {
      from = "emailing@make.org"
      from-name = "Make.org"
    }
  }

  mandatory-connection = false
  mandatory-connection = ${?MANDATORY_CONNECTION}
  max-history-proposals-per-page = 1000
  max-user-history-events = 10000

  newsletter-url = "https://webflow.com/api/v1/form/59833d390a24e50001b873d8"
  newsletter-url = ${?NEWSLETTER_URL}

  passivate-timeout = "2 minutes"

  lock-duration = "15 seconds"

  social-providers {
    google {
      api-key = "put here your google api key with access to the people API"
      client-id = "put here your google client id to use the api connect form"
      scopes = "profile email https://www.googleapis.com/auth/user.birthday.read"
    }

    facebook {}
  }

  user-token {
    validation-token-expires-in = "30 days"
    reset-token-expires-in = "1 day"
    reset-token-b2b-expires-in = "3 days"
  }

  user-validation {
    email {
      validators {
        always-validate {
          validator-class = "org.make.api.user.validation.AlwaysAuthorize"
          parameters {
            // If a validator needs specific configuration, put it in the parameters section
          }
        }
      }
    }

    // CSV with possible values: "age-is-required,underage-legal-consent"
    requirements = "age-is-required,underage-legal-consent"
    requirements = ${?USER_REQUIREMENTS}
  }

  secrets-configuration-path = "/etc/make/make-api.conf"

  security {
    secure-hash-salt = "jxu-qdimuh-yi-42"
    secure-hash-salt = ${?SECURE_HASH_SALT}
    secure-vote-salt = "d3f4u17v0735417"
    secure-vote-salt = ${?SECURE_VOTE_SALT}
    // The key here is a base64 of the secrey key.
    // The bytes inside must be well generated and have a size of 128 bits (16 bytes)
    aes-secret-key = "G9pPOCayHYlBnNAq1mCVqA=="
    aes-secret-key = ${?AES-SECRET-KEY}
  }

  storage {
    bucket-name = "assets"
    bucket-name = ${?STORAGE_BUCKET_NAME}
    base-url = "http://localhost:48080/v1.0/AUTH_test/assets"
    base-url = ${?CDN_BASE_URL}
    max-upload-file-size = 1048576
    max-upload-file-size = ${?MAX_UPLOAD_FILE_SIZE}
  }

  urls {
    front = "https://www.preprod.makeorg.tech"
    backoffice = "https://backoffice.preprod.makeorg.tech"
    widget = "https://widget.preprod.makeorg.tech"
  }

  webflow {
    dispatcher {
      type = Dispatcher
      executor = "thread-pool-executor"
      thread-pool-executor {
        fixed-pool-size = 8
      }
      throughput = 1
    }
    http-buffer-size = 100

    token = "webflow-token"
    token = ${?WEBFLOW_TOKEN}

    api-url = "https://api.webflow.com"
    blog-url = "https://make-org-site-corpo-46934932a95d560c065.webflow.io"
    collections-ids {
      posts = "5eddf33b5e82236441826e4e"
      posts = ${?WEBFLOW_COLLECTION_ID_POSTS}
    }
    rate-limit-per-minute = 60
  }

  zookeeper {
    url = "localhost:12181"
    url = ${?ZOOKEEPER_URL}
  }
  
}

make-openstack {
  authentication {
    keystone-version = "keystone-V1"
    base-url = "http://localhost:48080/auth/v1.0"
    tenant-name = "test"
    username = "tester"
    password = "testing"
    region = ""
  }

  storage {
    init-containers = [${make-api.storage.bucket-name}]
  }
}
