akka {

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  cluster {

    //    This can be used to react to down nodes
    //    downing-provider-class = "org.make.api.technical.cluster.MakeDowningProvider"

    role {
      seed {
        min-nr-of-members = 1
      }
      worker {
        min-nr-of-members = 1
      }
    }
    roles = ["seed", "worker"]
    seed-nodes = []

    sharding {
      guardian-name = sharding
      remember-entities = on
      state-store-mode = persistence
      role = "worker"

      snapshot-plugin-id = "cassandra-snapshot-store"
      journal-plugin-id = "cassandra-journal"
    }
  }

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  persistence {
    journal {
      plugin = cassandra-journal
    }
    snapshot-store {
      plugin = cassandra-snapshot-store
    }
    role = "worker"
  }

  remote {
    log-remote-lifecycle-events = on
    netty.tcp {
      hostname = "127.0.0.1"
      hostname = ${?TCP_HOST}
      port = 2551
      port = ${?TCP_PORT}
    }
  }

}

kamon {

  jmx {
    subscriptions {
      histogram = ["**"]
      min-max-counter = ["**"]
      gauge = ["**"]
      counter = ["**"]
      trace = ["**"]
      trace-segment = ["**"]
      akka-actor = ["**"]
      akka-dispatcher = ["**"]
      akka-router = ["**"]
      system-metric = ["**"]
      http-server = ["**"]
    }
  }

  modules {
    kamon-mxbeans {
      auto-start = no
      requires-aspectj = no
    }
    akka-actor {
      auto-start = yes
      requires-aspectj = yes
    }
    akka-dispatcher {
      auto-start = yes
      requires-aspectj = yes
    }
    akka-router {
      auto-start = yes
      requires-aspectj = yes
    }
  }

  # What should be recorder
  metric {
    filters {
      akka-actor {
        includes = ["**"]
        excludes = []
      }
      akka-dispatcher {
        includes = ["**"]
      }
      akka-router {
        includes = [ "**" ]
      }

      trace {
        includes = ["**"]
        excludes = []
      }
    }
  }
}

make-api {

  cluster {
    # Name of the akka actor systems, to allow multiple systems on the same consul
    name = "make-local"
    name = ${?CONTEXT_NAME}

    backend = "consul"

    consul {
      http-url = "http://localhost:8500"
      http-url = ${?CONSUL_URL}
    }

    # Interval on which heartbeat is updated
    heartbeat-interval = "30 seconds"
    # Time of the consul session, kept small in order to react quickly on seeds down
    session-timeout = "30 seconds"
    # Number of connection retries before trying to become a seed at start time
    retries-before-seeding = 3
    # duration between each session renew
    session-renew-interval = "20 seconds"
    # duration needed to declare a node as down
    node-timeout = "2 minutes"
    # interval to cleanup timeout nodes
    cleanup-interval = "1 hour"

  }

  database {
    jdbc-url = "jdbc:postgresql://localhost:26257/makeapi"
    jdbc-url = ${?JDBC_URL}
    user = "root"
    password = ""
    pools {
      read {
        connections = 50
      }
      write {
        connections = 20
      }
    }
    auto-create-db-schemas = true
  }

  dev {
    send-test-data = true
  }

  elasticSearch {
    host = "localhost"
    port = 9200
  }

  http {
    host = "0.0.0.0"
    host = ${?HOST}
    port = 9000
    port = ${?PORT}
  }

  kafka {
    connection-string = "localhost:9092"
    connection-string = ${?KAFKA_URI}
    poll-timeout = 10000
    schema-registry = "http://localhost:18081"
    schema-registry = ${?AVRO_REGISTRY_URL}
    topics {
      citizens = "citizens"
      propositions = "propositions"
      votes = "votes"
    }
  }

  passivate-timeout = "2 minutes"
}
